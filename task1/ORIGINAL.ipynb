{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 9291.681683,
      "end_time": "2021-08-29T17:46:57.805996",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2021-08-29T15:12:06.124313",
      "version": "2.3.3"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 10819976,
          "sourceType": "datasetVersion",
          "datasetId": 6717840
        }
      ],
      "dockerImageVersionId": 30887,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "id": "df4b393b-f46f-45fa-8ba6-a74f9dfb01bd",
      "cell_type": "code",
      "source": [
        "!pip install torch_fidelity"
      ],
      "metadata": {
        "trusted": true,
        "id": "df4b393b-f46f-45fa-8ba6-a74f9dfb01bd"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "409ea73f-b928-4e03-bc93-65204998136c",
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import itertools\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "\"\"\"\n",
        "Step 1. Define Generator\n",
        "\"\"\"\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, in_channels):\n",
        "        super(Generator, self).__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x\n",
        "\n",
        "\"\"\"\n",
        "Step 2. Define Discriminator\n",
        "\"\"\"\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, in_channels):\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, 64, kernel_size=4, stride=2, padding=1),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "\"\"\"\n",
        "Step 3. Define Loss\n",
        "\"\"\"\n",
        "criterion_GAN =\n",
        "criterion_cycle =\n",
        "criterion_identity =\n",
        "\n",
        "\"\"\"\n",
        "Step 4. Initalize G and DÂ¶\n",
        "\"\"\"\n",
        "G_AB = Generator(3)\n",
        "D_B = Discriminator(3)\n",
        "G_BA = Generator(3)\n",
        "D_A = Discriminator(3)\n",
        "\n",
        "## Total parameters in CycleGAN should be less than 60MB\n",
        "total_params = sum(p.numel() for p in G_AB.parameters()) + \\\n",
        "               sum(p.numel() for p in G_BA.parameters()) + \\\n",
        "               sum(p.numel() for p in D_A.parameters()) + \\\n",
        "               sum(p.numel() for p in D_B.parameters())\n",
        "\n",
        "\n",
        "total_params_million = total_params / (1024 * 1024)\n",
        "print(f'Total parameters in CycleGAN model: {total_params_million:.2f} million')\n",
        "\n",
        "cuda = torch.cuda.is_available()\n",
        "print(f'cuda: {cuda}')\n",
        "if cuda:\n",
        "    G_AB = G_AB.cuda()\n",
        "    D_B = D_B.cuda()\n",
        "    G_BA = G_BA.cuda()\n",
        "    D_A = D_A.cuda()\n",
        "\n",
        "criterion_GAN = criterion_GAN.cuda()\n",
        "criterion_cycle = criterion_cycle.cuda()\n",
        "criterion_identity = criterion_identity.cuda()\n",
        "\n",
        "\"\"\"\n",
        "Step 5. Configure Optimizers\n",
        "\"\"\"\n",
        "lr =\n",
        "optimizer_G = torch.optim.Adam(itertools.chain(G_AB.parameters(), G_BA.parameters()), lr=lr)\n",
        "optimizer_D_A = torch.optim.Adam(D_A.parameters(), lr=lr)\n",
        "optimizer_D_B = torch.optim.Adam(D_B.parameters(), lr=lr)\n",
        "\n",
        "\"\"\"\n",
        "Step 6. DataLoader\n",
        "\"\"\"\n",
        "class ImageDataset(Dataset):\n",
        "    def __init__(self, data_dir, mode='train', transforms=None):\n",
        "        A_dir = os.path.join(data_dir, 'VAE_generation/train') # modification forbidden\n",
        "        B_dir = os.path.join(data_dir, 'VAE_generation_Cartoon/train')  # modification forbidden\n",
        "\n",
        "        if mode == 'train':\n",
        "            self.files_A = [os.path.join(A_dir, name) for name in sorted(os.listdir(A_dir))[:200]] # can be modified\n",
        "            self.files_B = [os.path.join(B_dir, name) for name in sorted(os.listdir(B_dir))[:200]] # can be modified\n",
        "        elif mode == 'valid':\n",
        "            self.files_A = [os.path.join(A_dir, name) for name in sorted(os.listdir(A_dir))[200:250]] # can be modified\n",
        "            self.files_B = [os.path.join(B_dir, name) for name in sorted(os.listdir(B_dir))[200:250]] # can be modified\n",
        "\n",
        "        self.transforms = transforms\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.files_A)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        file_A = self.files_A[index]\n",
        "        file_B = self.files_B[index]\n",
        "\n",
        "        img_A = Image.open(file_A)\n",
        "        img_B = Image.open(file_B)\n",
        "\n",
        "        if self.transforms is not None:\n",
        "            img_A = self.transforms(img_A)\n",
        "            img_B = self.transforms(img_B)\n",
        "\n",
        "        return img_A, img_B\n",
        "\n",
        "data_dir = '/kaggle/input/group-project/image_image_translation'\n",
        "\n",
        "image_size = (256, 256)\n",
        "transforms_ = transforms.Compose([\n",
        "    transforms.Resize(image_size),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "batch_size = 5\n",
        "\n",
        "trainloader = DataLoader(\n",
        "    ImageDataset(data_dir, mode='train', transforms=transforms_),\n",
        "    batch_size = batch_size,\n",
        "    shuffle = True,\n",
        "    num_workers = 3\n",
        ")\n",
        "\n",
        "validloader = DataLoader(\n",
        "    ImageDataset(data_dir, mode='valid', transforms=transforms_),\n",
        "    batch_size = batch_size,\n",
        "    shuffle = False,\n",
        "    num_workers = 3\n",
        ")\n",
        "\n",
        "Tensor = torch.cuda.FloatTensor if cuda else torch.Tensor\n",
        "\n",
        "\"\"\"\n",
        "Step 7. Training\n",
        "\"\"\"\n",
        "Tensor = torch.cuda.FloatTensor if cuda else torch.Tensor\n",
        "\n",
        "SEED = 42\n",
        "print(\"Random Seed:\", SEED)\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "\n",
        "for epoch in range(n_epoches):\n",
        "    for i, (real_A, real_B) in enumerate(trainloader):\n",
        "        real_A, real_B = real_A.type(Tensor), real_B.type(Tensor)\n",
        "\n",
        "        # groud truth\n",
        "        out_shape = [real_A.size(0), 1, real_A.size(2)//D_A.scale_factor, real_A.size(3)//D_A.scale_factor]\n",
        "        valid = torch.ones(out_shape).type(Tensor)\n",
        "        fake = torch.zeros(out_shape).type(Tensor)\n",
        "\n",
        "        \"\"\"Train Generators\"\"\"\n",
        "        # set to training mode in the begining, because sample_images will set it to eval mode\n",
        "        G_AB.train()\n",
        "        G_BA.train()\n",
        "\n",
        "        optimizer_G.zero_grad()\n",
        "\n",
        "        fake_B = G_AB(real_A)\n",
        "        fake_A = G_BA(real_B)\n",
        "\n",
        "        # identity loss\n",
        "        loss_id_A = criterion_identity(fake_B, real_A)\n",
        "        loss_id_B = criterion_identity(fake_A, real_B)\n",
        "        loss_identity = (loss_id_A + loss_id_B) / 2\n",
        "\n",
        "        # GAN loss, train G to make D think it's true\n",
        "        loss_GAN_AB = criterion_GAN(D_B(fake_B), valid)\n",
        "        loss_GAN_BA = criterion_GAN(D_A(fake_A), valid)\n",
        "        loss_GAN = (loss_GAN_AB + loss_GAN_BA) / 2\n",
        "\n",
        "        # cycle loss\n",
        "        recov_A = G_BA(fake_B)\n",
        "        recov_B = G_AB(fake_A)\n",
        "        loss_cycle_A = criterion_cycle(recov_A, real_A)\n",
        "        loss_cycle_B = criterion_cycle(recov_B, real_B)\n",
        "        loss_cycle = (loss_cycle_A + loss_cycle_B) / 2\n",
        "\n",
        "        # G totol loss\n",
        "        weight1 =\n",
        "        weight2 =\n",
        "        weight3 =\n",
        "        loss_G = weight1*loss_identity + weight2*loss_GAN + weight3*loss_cycle\n",
        "\n",
        "        loss_G.backward()\n",
        "        optimizer_G.step()\n",
        "\n",
        "        \"\"\"Train Discriminator A\"\"\"\n",
        "        optimizer_D_A.zero_grad()\n",
        "\n",
        "        loss_real = criterion_GAN(D_A(real_A), valid)\n",
        "        loss_fake = criterion_GAN(D_A(fake_A.detach()), fake)\n",
        "        loss_D_A = (loss_real + loss_fake) / 2\n",
        "\n",
        "        loss_D_A.backward()\n",
        "        optimizer_D_A.step()\n",
        "\n",
        "        \"\"\"Train Discriminator B\"\"\"\n",
        "        optimizer_D_B.zero_grad()\n",
        "\n",
        "        loss_real = criterion_GAN(D_B(real_B), valid)\n",
        "        loss_fake = criterion_GAN(D_B(fake_B.detach()), fake)\n",
        "        loss_D_B = (loss_real + loss_fake) / 2\n",
        "\n",
        "        loss_D_B.backward()\n",
        "        optimizer_D_B.step()\n",
        "\n",
        "    # validation\n",
        "    if (epoch+1) % 10 == 0:\n",
        "        valid_real_A, valid_real_B = next(iter(testloader))\n",
        "        sample_images(valid_real_A, valid_real_B)\n",
        "\n",
        "        loss_D = (loss_D_A + loss_D_B) / 2\n",
        "        print(f'[Epoch {epoch+1}/{n_epoches}]')\n",
        "        print(f'[G loss: {loss_G.item()} | identity: {loss_identity.item()} GAN: {loss_GAN.item()} cycle: {loss_cycle.item()}]')\n",
        "        print(f'[D loss: {loss_D.item()} | D_A: {loss_D_A.item()} D_B: {loss_D_B.item()}]')\n",
        "\n",
        "\"\"\"\n",
        "Step 8. Generate Images\n",
        "\"\"\"\n",
        "## Raw Image to Cartoon Image\n",
        "test_dir = os.path.join(data_dir, 'VAE_generation/test') # modification forbidden\n",
        "files = [os.path.join(test_dir, name) for name in os.listdir(test_dir)]\n",
        "len(files)\n",
        "\n",
        "save_dir = '../Cartoon_images'\n",
        "if not os.path.exists(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "\n",
        "generate_transforms = transforms.Compose([\n",
        "    transforms.Resize(image_size),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "to_image = transforms.ToPILImage()\n",
        "\n",
        "G_BA.eval()\n",
        "for i in range(0, len(files), batch_size):\n",
        "    # read images\n",
        "    imgs = []\n",
        "    for j in range(i, min(len(files), i+batch_size)):\n",
        "        img = Image.open(files[j])\n",
        "        img = generate_transforms(img)\n",
        "        imgs.append(img)\n",
        "    imgs = torch.stack(imgs, 0).type(Tensor)\n",
        "\n",
        "    # generate\n",
        "    fake_imgs = G_BA(imgs).detach().cpu()\n",
        "\n",
        "    # save\n",
        "    for j in range(fake_imgs.size(0)):\n",
        "        img = fake_imgs[j].squeeze().permute(1, 2, 0)\n",
        "        img_arr = img.numpy()\n",
        "        img_arr = (img_arr - np.min(img_arr)) * 255 / (np.max(img_arr) - np.min(img_arr))\n",
        "        img_arr = img_arr.astype(np.uint8)\n",
        "\n",
        "        img = to_image(img_arr)\n",
        "        _, name = os.path.split(files[i+j])\n",
        "        img.save(os.path.join(save_dir, name))\n",
        "\n",
        "metrics = torch_fidelity.calculate_metrics(\n",
        "    input1=\"/kaggle/input/group-project/image_image_translation/VAE_generation_Cartoon/test\",\n",
        "    input2=save_dir,\n",
        "    cuda=True,\n",
        "    fid=True,\n",
        "    isc=True\n",
        ")\n",
        "\n",
        "fid_score = metrics[\"frechet_inception_distance\"]\n",
        "is_score = metrics[\"inception_score_mean\"]\n",
        "\n",
        "if is_score > 0:\n",
        "    s_value_1 = np.sqrt(fid_score / is_score)\n",
        "    print(\"Geometric Mean Score:\", s_value)\n",
        "else:\n",
        "    print(\"IS is 0, GMS cannot be computed!\")\n",
        "\n",
        "\n",
        "## Cartoon Image to Raw Image\n",
        "\n",
        "test_dir = os.path.join(data_dir, 'VAE_generation_Cartoon/test')\n",
        "files = [os.path.join(test_dir, name) for name in os.listdir(test_dir)]\n",
        "len(files)\n",
        "\n",
        "save_dir = '../Raw_images'\n",
        "if not os.path.exists(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "\n",
        "generate_transforms = transforms.Compose([\n",
        "    transforms.Resize(image_size),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "to_image = transforms.ToPILImage()\n",
        "\n",
        "G_BA.eval()\n",
        "for i in range(0, len(files), batch_size):\n",
        "    # read images\n",
        "    imgs = []\n",
        "    for j in range(i, min(len(files), i+batch_size)):\n",
        "        img = Image.open(files[j])\n",
        "        img = generate_transforms(img)\n",
        "        imgs.append(img)\n",
        "    imgs = torch.stack(imgs, 0).type(Tensor)\n",
        "\n",
        "    # generate\n",
        "    fake_imgs = G_BA(imgs).detach().cpu()\n",
        "\n",
        "    # save\n",
        "    for j in range(fake_imgs.size(0)):\n",
        "        img = fake_imgs[j].squeeze().permute(1, 2, 0)\n",
        "        img_arr = img.numpy()\n",
        "        img_arr = (img_arr - np.min(img_arr)) * 255 / (np.max(img_arr) - np.min(img_arr))\n",
        "        img_arr = img_arr.astype(np.uint8)\n",
        "\n",
        "        img = to_image(img_arr)\n",
        "        _, name = os.path.split(files[i+j])\n",
        "        img.save(os.path.join(save_dir, name))\n",
        "\n",
        "metrics = torch_fidelity.calculate_metrics(\n",
        "    input1=\"/kaggle/input/group-project/image_image_translation/VAE_generation/test\",\n",
        "    input2=save_dir,\n",
        "    cuda=True,\n",
        "    fid=True,\n",
        "    isc=True\n",
        ")\n",
        "\n",
        "fid_score = metrics[\"frechet_inception_distance\"]\n",
        "is_score = metrics[\"inception_score_mean\"]\n",
        "\n",
        "if is_score > 0:\n",
        "    s_value_2 = np.sqrt(fid_score / is_score)\n",
        "    print(\"Geometric Mean Score:\", s_value_2)\n",
        "else:\n",
        "    print(\"IS is 0, GMS cannot be computed!\")\n",
        "\n",
        "\n",
        "s_value = np.round((s_value_1+s_value_2)/2, 5)\n",
        "df = pd.DataFrame({'id': [1], 'label': [s_value]})\n",
        "\n",
        "csv_path = \"Username.csv\"\n",
        "df.to_csv(csv_path, index=False)\n",
        "\n",
        "print(f\"CSV saved to {csv_path}\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "409ea73f-b928-4e03-bc93-65204998136c"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}