{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "aa29655b",
      "metadata": {},
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d3d4b1e",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import itertools\n",
        "import torch_fidelity\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.datasets import ImageFolder\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "import pandas as pd\n",
        "import random\n",
        "import torch.nn.functional as F\n",
        "from piqa import SSIM\n",
        "import sys\n",
        "from tqdm import tqdm\n",
        "\n",
        "# SEED = 42\n",
        "SEED = random.randrange(2**32 - 1)\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "print(\"Random Seed:\", SEED)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b974f4bc",
      "metadata": {},
      "source": [
        "# Work"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d800396",
      "metadata": {},
      "outputs": [],
      "source": [
        "from models.generators import UNetGenerator\n",
        "from models.discriminators import PatchDiscriminator, RandomKaggleDiscriminator\n",
        "\n",
        "\"\"\"\n",
        "Step 4. Initalize G and DÂ¶\n",
        "\"\"\"\n",
        "G_AB = UNetGenerator()\n",
        "D_B = PatchDiscriminator()\n",
        "G_BA = UNetGenerator()\n",
        "D_A = PatchDiscriminator()\n",
        "\n",
        "## Total parameters in CycleGAN should be less than 60MB\n",
        "total_params = sum(p.numel() for p in G_AB.parameters()) + \\\n",
        "               sum(p.numel() for p in G_BA.parameters()) + \\\n",
        "               sum(p.numel() for p in D_A.parameters()) + \\\n",
        "               sum(p.numel() for p in D_B.parameters())\n",
        "\n",
        "\n",
        "total_params_million = total_params / (1024 * 1024)\n",
        "print(f'Total parameters in CycleGAN model: {total_params_million:.2f} million')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a410e1d",
      "metadata": {},
      "outputs": [],
      "source": [
        "def denormalize(tensor, mean=0.5, std=0.5):\n",
        "    \"\"\"\n",
        "    Denormalize a tensor normalized with mean and std.\n",
        "    Args:\n",
        "        tensor (torch.Tensor): Normalized tensor.\n",
        "        mean (float): Mean used for normalization.\n",
        "        std (float): Std used for normalization.\n",
        "    Returns:\n",
        "        torch.Tensor: Denormalized tensor.\n",
        "    \"\"\"\n",
        "    return tensor * std + mean\n",
        "\n",
        "\n",
        "class HingeAdversarialLoss(nn.Module):\n",
        "    def forward(self, pred, is_real):\n",
        "        if is_real:\n",
        "            return F.relu(1 - pred).mean()\n",
        "        else:\n",
        "            return F.relu(1 + pred).mean()\n",
        "\n",
        "class EdgeConsistencyLoss(nn.Module):\n",
        "    def __init__(self, data_range=1.0):\n",
        "        super().__init__()\n",
        "        self.ssim = SSIM(n_channels=1, value_range=data_range)\n",
        "\n",
        "        # Sobel kernels for edge detection\n",
        "        sobel_x = torch.tensor([[[[-1., 0., 1.], \n",
        "                                  [-2., 0., 2.], \n",
        "                                  [-1., 0., 1.]]]])\n",
        "        sobel_y = torch.tensor([[[[-1., -2., -1.], \n",
        "                                  [0., 0., 0.], \n",
        "                                  [1., 2., 1.]]]])\n",
        "        \n",
        "        self.register_buffer('sobel_x', sobel_x)\n",
        "        self.register_buffer('sobel_y', sobel_y)\n",
        "\n",
        "    def rgb_to_grayscale(self, x):\n",
        "        return 0.299 * x[:, 0:1] + 0.587 * x[:, 1:2] + 0.114 * x[:, 2:3]\n",
        "\n",
        "    def get_edge_map(self, x):\n",
        "        x_gray = self.rgb_to_grayscale(x)\n",
        "        \n",
        "        grad_x = F.conv2d(x_gray, self.sobel_x, padding=1)\n",
        "        grad_y = F.conv2d(x_gray, self.sobel_y, padding=1)\n",
        "        \n",
        "        edge_mag = torch.sqrt(grad_x**2 + grad_y**2 + 1e-8)\n",
        "        \n",
        "        # Normalize edge magnitude to [0, 1]\n",
        "        min_val = edge_mag.min().detach()\n",
        "        max_val = edge_mag.max().detach()\n",
        "        return (edge_mag - min_val) / (max_val - min_val + 1e-8)\n",
        "\n",
        "    def forward(self, x, y):\n",
        "        # Denormalize inputs from [-1, 1] back to [0, 1]\n",
        "        x = denormalize(x, mean=0.5, std=0.5)\n",
        "        y = denormalize(y, mean=0.5, std=0.5)\n",
        "\n",
        "        # Compute edge maps\n",
        "        edge_x = self.get_edge_map(x)\n",
        "        edge_y = self.get_edge_map(y)\n",
        "\n",
        "        # Compute SSIM between edge maps\n",
        "        return 1.0 - self.ssim(edge_x, edge_y)\n",
        "\n",
        "\n",
        "class IdentityPreservationLoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.mse_loss = nn.MSELoss()\n",
        "        self.ssim = EdgeConsistencyLoss(data_range=1.0)\n",
        "        \n",
        "    def forward(self, input, target):\n",
        "        ssim_loss = self.ssim(input, target)\n",
        "        gram_input = self.gram_matrix(input)\n",
        "        gram_target = self.gram_matrix(target)\n",
        "        style_loss = self.mse_loss(gram_input, gram_target)\n",
        "        return 0.7 * ssim_loss + 0.3 * style_loss\n",
        "    \n",
        "    def gram_matrix(self, x):\n",
        "        b, c, h, w = x.size()\n",
        "        features = x.view(b, c, h * w)\n",
        "        gram = torch.bmm(features, features.transpose(1, 2))\n",
        "        return gram / (c * h * w)\n",
        "\n",
        "class SobelOperator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        kernel_x = torch.tensor([[[[-1., 0., 1.],\n",
        "                                   [-2., 0., 2.],\n",
        "                                   [-1., 0., 1.]]]])\n",
        "        kernel_y = torch.tensor([[[[-1., -2., -1.],\n",
        "                                   [0., 0., 0.],\n",
        "                                   [1., 2., 1.]]]])\n",
        "        \n",
        "        self.register_buffer('kernel_x', kernel_x)\n",
        "        self.register_buffer('kernel_y', kernel_y)\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, c, h, w = x.size()\n",
        "        \n",
        "        # Expand kernels for multi-channel input\n",
        "        kernel_x = self.kernel_x.repeat(c, 1, 1, 1)\n",
        "        kernel_y = self.kernel_y.repeat(c, 1, 1, 1)\n",
        "        \n",
        "        grad_x = F.conv2d(x, kernel_x, padding=1, groups=c)\n",
        "        grad_y = F.conv2d(x, kernel_y, padding=1, groups=c)\n",
        "        return torch.sqrt(grad_x**2 + grad_y**2 + 1e-8)\n",
        "\n",
        "class GradientPreservationLoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.sobel = SobelOperator()\n",
        "        \n",
        "    def forward(self, generated, target):\n",
        "        grad_gen = self.sobel(generated)\n",
        "        grad_target = self.sobel(target)\n",
        "        return F.l1_loss(grad_gen, grad_target)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1eafc098",
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Step 3. Define Loss\n",
        "\"\"\"\n",
        "# criterion_GAN = HingeAdversarialLoss()\n",
        "criterion_GAN = nn.BCELoss()\n",
        "criterion_cycle = nn.L1Loss()\n",
        "criterion_identity = IdentityPreservationLoss()\n",
        "criterion_gradient = GradientPreservationLoss()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5731f5a",
      "metadata": {},
      "outputs": [],
      "source": [
        "lambda_adv = 1.0\n",
        "lambda_cycle = 10.0\n",
        "lambda_edge = 5.0\n",
        "lambda_identity = 2.0\n",
        "lambda_fm = 1.0\n",
        "lambda_grad = 3.0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0a855d14",
      "metadata": {},
      "outputs": [],
      "source": [
        "if torch.cuda.is_available():\n",
        "    print(f\"Current GPU: {torch.cuda.current_device()}\")\n",
        "    print(f\"Current GPU name: {torch.cuda.get_device_name(torch.cuda.current_device())}\")\n",
        "    device = torch.device(\"cuda\")\n",
        "    G_AB = G_AB.cuda()\n",
        "    D_B = D_B.cuda()\n",
        "    G_BA = G_BA.cuda()\n",
        "    D_A = D_A.cuda()\n",
        "    criterion_GAN = criterion_GAN.cuda()\n",
        "    criterion_cycle = criterion_cycle.cuda()\n",
        "    criterion_identity = criterion_identity.cuda()\n",
        "    Tensor = torch.cuda.FloatTensor\n",
        "else:\n",
        "    print(\"PyTorch does not have access to GPU, falling back to CPU\")\n",
        "    Tensor = torch.Tensor\n",
        "    device = torch.device(\"cpu\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b2dcad7",
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Step 5. Configure Optimizers\n",
        "\"\"\"\n",
        "\n",
        "def get_lr_scheduler(optimizer, n_epochs=100, n_epochs_decay=100, lr_policy='linear'):\n",
        "    if lr_policy == 'linear':\n",
        "        def lambda_rule(epoch):\n",
        "            # Keep constant for first n_epochs, then linearly decay to zero\n",
        "            lr_l = 1.0 - max(0, epoch - n_epochs) / float(n_epochs_decay + 1)\n",
        "            return lr_l\n",
        "        scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda_rule)\n",
        "    else:\n",
        "        raise NotImplementedError(f'learning rate policy {lr_policy} not implemented')\n",
        "    return scheduler\n",
        "\n",
        "# Optimizer setup\n",
        "optimizer_G = torch.optim.Adam(itertools.chain(G_AB.parameters(), G_BA.parameters()),\n",
        "                               lr=0.0002, betas=(0.5, 0.999))\n",
        "optimizer_D = torch.optim.Adam(itertools.chain(D_A.parameters(), D_B.parameters()),\n",
        "                               lr=0.0002, betas=(0.5, 0.999))\n",
        "\n",
        "# Learning rate schedulers\n",
        "scheduler_G = get_lr_scheduler(optimizer_G, n_epochs=100, n_epochs_decay=100)\n",
        "scheduler_D = get_lr_scheduler(optimizer_D, n_epochs=100, n_epochs_decay=100)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2479d552",
      "metadata": {},
      "outputs": [],
      "source": [
        "from typing import Callable, Literal\n",
        "\n",
        "\n",
        "def run_one_epoch(\n",
        "    G_AB: nn.Module,\n",
        "    G_BA: nn.Module,\n",
        "    D_A: nn.Module,\n",
        "    D_B: nn.Module,\n",
        "    state: Literal[\"train\", \"eval\"],\n",
        "    dataloader: DataLoader,\n",
        "    criterion_identity: Callable,\n",
        "    criterion_GAN: Callable,\n",
        "    criterion_cycle: Callable,\n",
        "    optimizer_G: torch.optim.Optimizer,\n",
        "    optimizer_D: torch.optim.Optimizer,\n",
        "    # optimizer_D_A: torch.optim.Optimizer,\n",
        "    # optimizer_D_B: torch.optim.Optimizer,\n",
        "    weights: tuple[float, float, float],\n",
        ") -> dict[str, float]:\n",
        "\n",
        "    # Set training/evaluation mode only when necessary\n",
        "    if state == \"train\":\n",
        "        G_AB.train(), G_BA.train()\n",
        "        D_A.train(), D_B.train()\n",
        "    else:\n",
        "        G_AB.eval(), G_BA.eval()\n",
        "        D_A.eval(), D_B.eval()\n",
        "\n",
        "    weight_identity, weight_GAN, weight_cycle = weights\n",
        "\n",
        "    running_losses = {\n",
        "        \"G\": 0.0, \"D_A\": 0.0, \"D_B\": 0.0,\n",
        "        \"identity\": 0.0, \"GAN\": 0.0, \"cycle\": 0.0\n",
        "    }\n",
        "\n",
        "    # No gradient tracking during evaluation\n",
        "    torch.set_grad_enabled(state == \"train\")\n",
        "    with tqdm(dataloader, unit=\"batch\", desc=\"Training\" if state == \"train\" else \"Validation\") as tepoch:\n",
        "        for real_A, real_B in tepoch:\n",
        "            optimizer_G.zero_grad()\n",
        "            real_A, real_B = real_A.to(device, dtype=torch.float32, non_blocking=True), real_B.to(device, dtype=torch.float32, non_blocking=True)\n",
        "\n",
        "            # Prepare ground truth labels\n",
        "            valid, fake = torch.ones(real_A.size(0), 1, device=device, requires_grad=False), torch.zeros(real_A.size(0), 1, device=device, requires_grad=False)\n",
        "\n",
        "            # Train Generators\n",
        "            fake_B = G_AB(real_A)\n",
        "            fake_A = G_BA(real_B)\n",
        "\n",
        "            # Identity loss\n",
        "            loss_id_A = criterion_identity(fake_B, real_A)\n",
        "            loss_id_B = criterion_identity(fake_A, real_B)\n",
        "            loss_identity = (loss_id_A + loss_id_B) / 2\n",
        "\n",
        "            # GAN loss\n",
        "            loss_GAN_AB = criterion_GAN(D_B(fake_B), valid)\n",
        "            loss_GAN_BA = criterion_GAN(D_A(fake_A), valid)\n",
        "            loss_GAN = (loss_GAN_AB + loss_GAN_BA) / 2\n",
        "\n",
        "            # Cycle loss\n",
        "            recov_A = G_BA(fake_B)\n",
        "            recov_B = G_AB(fake_A)\n",
        "            loss_cycle_A = criterion_cycle(recov_A, real_A)\n",
        "            loss_cycle_B = criterion_cycle(recov_B, real_B)\n",
        "            loss_cycle = (loss_cycle_A + loss_cycle_B) / 2\n",
        "\n",
        "            # Total generator loss\n",
        "            loss_G = weight_identity * loss_identity + weight_GAN * loss_GAN + weight_cycle * loss_cycle\n",
        "            if state == \"train\":\n",
        "                loss_G.backward()\n",
        "                optimizer_G.step()\n",
        "\n",
        "                optimizer_D.zero_grad()\n",
        "                # Train Discriminators\n",
        "                # optimizer_D_A.zero_grad()\n",
        "                # optimizer_D_B.zero_grad()\n",
        "                \n",
        "                loss_real_A = criterion_GAN(D_A(real_A), valid)\n",
        "                loss_fake_A = criterion_GAN(D_A(fake_A.detach()), fake)\n",
        "                loss_D_A = (loss_real_A + loss_fake_A) / 2\n",
        "                \n",
        "                loss_real_B = criterion_GAN(D_B(real_B), valid)\n",
        "                loss_fake_B = criterion_GAN(D_B(fake_B.detach()), fake)\n",
        "                loss_D_B = (loss_real_B + loss_fake_B) / 2\n",
        "                \n",
        "                loss_D = (loss_D_A + loss_D_B)\n",
        "                loss_D.backward()\n",
        "                optimizer_D.step()\n",
        "                # optimizer_D_A.step()\n",
        "                # optimizer_D_B.step()\n",
        "\n",
        "            # Accumulate losses\n",
        "            running_losses[\"G\"] += loss_G.item()\n",
        "            running_losses[\"D_A\"] += loss_D_A.item()\n",
        "            running_losses[\"D_B\"] += loss_D_B.item()\n",
        "            running_losses[\"identity\"] += loss_identity.item()\n",
        "            running_losses[\"GAN\"] += loss_GAN.item()\n",
        "            running_losses[\"cycle\"] += loss_cycle.item()\n",
        "\n",
        "    print(f'[G loss: {loss_G.item()} | identity: {loss_identity.item()} GAN: {loss_GAN.item()} cycle: {loss_cycle.item()}]')\n",
        "    print(f'[D loss: {loss_D.item()} | D_A: {loss_D_A.item()} D_B: {loss_D_B.item()}]')\n",
        "    # Average the losses over the dataset\n",
        "    return {k: v / len(dataloader) for k, v in running_losses.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e619ac7",
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Step 6. DataLoader\n",
        "\"\"\"\n",
        "from CustomImageDataset import CustomImageDataset as ImageDataset\n",
        "# data_dir = '/kaggle/input/group-project/image_image_translation'\n",
        "data_dir = ''\n",
        "\n",
        "image_size = (128, 128)\n",
        "transforms_ = transforms.Compose([\n",
        "    transforms.Resize(image_size),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "loader_params = {\n",
        "    \"batch_size\": 20,\n",
        "    \"num_workers\": 2,\n",
        "    \"pin_memory\": False,\n",
        "    \"shuffle\": True,\n",
        "    # \"prefetch_factor\": 2,\n",
        "    \"persistent_workers\": True\n",
        "}\n",
        "\n",
        "\n",
        "trainloader = DataLoader(\n",
        "    ImageDataset(data_dir, mode='train', transform=transforms_),\n",
        "    **loader_params\n",
        ")\n",
        "\n",
        "loader_params[\"shuffle\"] = False\n",
        "validloader = DataLoader(\n",
        "    ImageDataset(data_dir, mode='valid', transform=transforms_),\n",
        "    **loader_params\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "409ea73f-b928-4e03-bc93-65204998136c",
      "metadata": {
        "id": "409ea73f-b928-4e03-bc93-65204998136c",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Step 7. Training\n",
        "\"\"\"\n",
        "n_epochs = 200\n",
        "for epoch in range(1, n_epochs + 1):\n",
        "    print(f'[Epoch {epoch}/{n_epochs}]')\n",
        "    run_one_epoch(\n",
        "        G_AB, G_BA, D_A, D_B, \"train\", trainloader,\n",
        "        criterion_identity, criterion_GAN, criterion_cycle,\n",
        "        optimizer_G, optimizer_D,\n",
        "        (lambda_identity, lambda_adv, lambda_cycle)\n",
        "    )\n",
        "\n",
        "    # validation\n",
        "    if epoch % 25 == 0:\n",
        "    #     valid_real_A, valid_real_B = next(iter(testloader))\n",
        "    #     sample_images(valid_real_A, valid_real_B)\n",
        "\n",
        "    #     loss_D = (loss_D_A + loss_D_B) / 2\n",
        "    #     print(f'[Epoch {epoch+1}/{n_epochs}]')\n",
        "    #     print(f'[G loss: {loss_G.item()} | identity: {loss_identity.item()} GAN: {loss_GAN.item()} cycle: {loss_cycle.item()}]')\n",
        "    #     print(f'[D loss: {loss_D.item()} | D_A: {loss_D_A.item()} D_B: {loss_D_B.item()}]')\n",
        "\n",
        "\n",
        "        # Save model checkpoints  \n",
        "        torch.save(G_AB.state_dict(), f'checkpoints/G_AB_{epoch}.pth')\n",
        "        torch.save(D_A.state_dict(), f'checkpoints/D_A_{epoch}.pth')\n",
        "        torch.save(G_BA.state_dict(), f'checkpoints/G_BA_{epoch}.pth')\n",
        "        torch.save(D_B.state_dict(), f'checkpoints/D_B_{epoch}.pth')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "52cb0fb1",
      "metadata": {},
      "source": [
        "# Output Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d70abd1",
      "metadata": {},
      "outputs": [],
      "source": [
        "from typing import Type\n",
        "def evaluate(\n",
        "    model: torch.nn.Module,\n",
        "    input_dir: str,\n",
        "    output_dir: str,\n",
        "    ref_dir: str,\n",
        "    batch_size: int,\n",
        "    image_size: int,\n",
        "    tensor_type: Type[torch.Tensor]\n",
        ") -> float:\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "\n",
        "    generate_transforms = transforms.Compose([\n",
        "        transforms.Resize(image_size),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ])\n",
        "\n",
        "    to_image = transforms.ToPILImage()\n",
        "\n",
        "    files = [os.path.join(input_dir, name) for name in os.listdir(input_dir)]\n",
        "\n",
        "    model.eval()\n",
        "    for i in range(0, len(files), batch_size):\n",
        "        # Read and transform images\n",
        "        imgs = [generate_transforms(Image.open(files[j])) for j in range(i, min(len(files), i + batch_size))]\n",
        "        imgs = torch.stack(imgs, 0).type(tensor_type)\n",
        "\n",
        "        # Generate images\n",
        "        fake_imgs = model(imgs).detach().cpu()\n",
        "\n",
        "        # Save generated images\n",
        "        for j in range(fake_imgs.size(0)):\n",
        "            img = fake_imgs[j].squeeze().permute(1, 2, 0).numpy()\n",
        "            img = (img - np.min(img)) * 255 / (np.max(img) - np.min(img))\n",
        "            img = to_image(img.astype(np.uint8))\n",
        "            _, name = os.path.split(files[i + j])\n",
        "            img.save(os.path.join(output_dir, name))\n",
        "\n",
        "    # Compute metrics\n",
        "    metrics: dict[str, float] = torch_fidelity.calculate_metrics(\n",
        "        input1=output_dir,\n",
        "        input2=ref_dir,\n",
        "        cuda=True,\n",
        "        fid=True,\n",
        "        isc=True\n",
        "    )\n",
        "\n",
        "    fid_score: float = metrics[\"frechet_inception_distance\"]\n",
        "    is_score: float = metrics[\"inception_score_mean\"]\n",
        "\n",
        "    if is_score > 0:\n",
        "        gms: float = np.sqrt(fid_score / is_score)\n",
        "        print(\"Geometric Mean Score:\", gms)\n",
        "        return gms, fid_score, is_score\n",
        "    else:\n",
        "        print(\"IS is 0, GMS cannot be computed!\")\n",
        "        return 0, 0, 0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "84d6ed27",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Parameters\n",
        "image_size = 128\n",
        "batch_size = loader_params[\"batch_size\"]\n",
        "\n",
        "# data_dir = '/kaggle/input/group-project/image_image_translation'\n",
        "data_dir = '.'\n",
        "\n",
        "\n",
        "def format_score(score):\n",
        "    return \"{:.4f}\".format(score).replace(\".\", \"_\")\n",
        "\n",
        "def report_score(s_value_1, fid_1, is_1, s_value_2, fid_2, is_2):\n",
        "    s_value = np.round((s_value_1+s_value_2)/2, 5)\n",
        "    df = pd.DataFrame({'id': [1], 'label': [s_value]})\n",
        "    filename = f\"{format_score(s_value)}-C[{format_score(s_value_1)}-{format_score(fid_1)}-{format_score(is_1)}]-R[{format_score(s_value_2)}-{format_score(fid_2)}-{format_score(is_2)}]\"\n",
        "\n",
        "    csv_path = filename+\".csv\"\n",
        "    df.to_csv(csv_path, index=False)\n",
        "\n",
        "    print(f\"CSV saved to {csv_path}\")\n",
        "\n",
        "for i in range(25, 201, 25):\n",
        "    G_AB.load_state_dict(torch.load(f'checkpoints/G_AB_{i}.pth'))\n",
        "    G_BA.load_state_dict(torch.load(f'checkpoints/G_BA_{i}.pth'))\n",
        "\n",
        "    # Raw to Cartoon\n",
        "    s_value_1, fid_1, is_1 = evaluate(\n",
        "        model=G_AB,\n",
        "        input_dir=os.path.join(data_dir, 'VAE_generation/test'),\n",
        "        output_dir='../Cartoon_images',\n",
        "        ref_dir=f\"{data_dir}/VAE_generation_Cartoon/test\",\n",
        "        batch_size=batch_size,\n",
        "        image_size=image_size,\n",
        "        tensor_type=Tensor\n",
        "    )\n",
        "\n",
        "    # Cartoon to Raw\n",
        "    s_value_2, fid_2, is_2 = evaluate(\n",
        "        model=G_BA,\n",
        "        input_dir=os.path.join(data_dir, 'VAE_generation_Cartoon/test'),\n",
        "        output_dir='../Raw_images',\n",
        "        ref_dir=f\"{data_dir}/VAE_generation/test\",\n",
        "        batch_size=batch_size,\n",
        "        image_size=image_size,\n",
        "        tensor_type=Tensor\n",
        "    )\n",
        "\n",
        "    report_score(s_value_1, fid_1, is_1, s_value_2, fid_2, is_2)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6d3ad489",
      "metadata": {},
      "source": [
        "# Clean Up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ae7c7ab",
      "metadata": {},
      "outputs": [],
      "source": [
        "import gc\n",
        "del G_AB, G_BA, D_A, D_B\n",
        "\n",
        "gc.collect()\n",
        "with torch.no_grad():\n",
        "    torch.cuda.empty_cache()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "datasetId": 6717840,
          "sourceId": 10819976,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30887,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "venv313",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.1"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 9291.681683,
      "end_time": "2021-08-29T17:46:57.805996",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2021-08-29T15:12:06.124313",
      "version": "2.3.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
